% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/g3_iterative.R
\name{g3_iterative}
\alias{g3_iterative}
\title{Perform multiple optimisation runs of a model, reweighting with each run}
\usage{
g3_iterative(
  gd,
  wgts = "WGTS",
  model,
  params.in,
  grouping = list(),
  use_parscale = TRUE,
  method = "BFGS",
  control = list(),
  shortcut = FALSE,
  cv_floor = 0,
  resume_final = FALSE,
  mc.cores = parallel::detectCores()
)
}
\arguments{
\item{gd}{Directory to store output}

\item{wgts}{Directory name within gd to store run outputs}

\item{model}{A G3 model, produced by g3_to_r() or g3_tmb_adfun()}

\item{params.in}{Initial parameters to use with the model}

\item{grouping}{List of component names to optmise together}

\item{use_parscale}{Logical indicating whether optim(control$parscale) should be used}

\item{method}{The optimisation method, see \code{\link[stats]{optim}}}

\item{control}{List of control options for optim, see \code{\link[stats]{optim}}}

\item{shortcut}{If TRUE, weights for each component will be approximated and a final optimisation performed}

\item{cv_floor}{Minimum value of survey components (adist_surveyindices) as 1/\code{cv_floor}, applied prior to second stage of iterations.}

\item{resume_final}{Logical value. If TRUE the re-weighting procedure starts at the second stage.}

\item{mc.cores}{number of cores used, defaults to the number of available cores}
}
\value{
Final set of parameters
}
\description{
An implementation of the iterative reweigthing of likelihood
components in gadget. It analyzes a given gadget model and, after
a series of optimisations where each likelihood component is
heavily weigthed, suggests a weigthing for the components based on
the respective variance.  If one (or more) components, other than
understocking and penalty, are 0 then the gadget optimisation with
the final weights will not be completed.
}
\details{
In Taylor et. al an objective reweighting scheme for likelihood
components is described for cod in Icelandic waters. The authors
nota that the issue of component weighting has been discussed for
some time, as the data sources have different natural scales (e.g
g vs. kg) that should not affect the outcome. A simple heuristic,
where the weights are the inverse of the initial sums of squares
for the respective component resulting in an initials score equal
to the number of components, is therfor often used. This has the
intutitive advantage of all components being normalised. There is
however a drawback to this since the component scores, given the
initial parametrisation, are most likely not equally far from
their respective optima resulting in sub-optimal weighting.  The
iterative reweighting heuristic tackles this problem by optimising
each component separately in order to determine the lowest
possible value for each component. This is then used to determine
the final weights.  The resoning for this approach is as follows:
Conceptually the likelihood components can be thought of as
residual sums of squares, and as such their variance can be
esimated by dividing the SS by the degrees of freedom. The optimal
weighting strategy is the inverse of the variance.  Here the
iteration starts with assigning the inverse SS as the initial
weight, that is the initial score of each component when
multiplied with the weight is 1. Then an optimisation run for each
component with the intial score for that component set to
10000. After the optimisation run the inverse of the resulting SS
is multiplied by the effective number of datapoints and used as
the final weight for that particular component.  The effective
number of datapoints is used as a proxy for the degrees of freedom
is determined from the number of non-zero datapoints. This is
viewed as satisfactory proxy when the dataset is large, but for
smaller datasets this could be a gross overestimate. In
particular, if the surveyindices are weigthed on their own while
the yearly recruitment is esimated they could be overfitted. If
there are two surveys within the year Taylor et. al suggest that
the corresponding indices from each survey are weigthed
simultaneously in order to make sure that there are at least two
measurement for each yearly recruit, this is done through
component grouping which is implemented.

Component grouping is oftern applied in cases where overfitting is likely,
and this can also happen with catch composition data as well as survey indices.

In addition to grouping, a maximum weight can be assigned survey indices vie the
cv_floor setting. The cv_floor parameter sets the minimum of the estimated component
variance and thus the maximum of the inverser variance.

Weights are calculated using inverse-variance weighting (\eqn{1/\sigma^2}), and as \code{1/pmax(variance, cv_floor)}, hence the minimum value for survey components is 1/\code{cv_floor}. Use smaller \code{cv_floor} values to increase the weight of survey components.
}
